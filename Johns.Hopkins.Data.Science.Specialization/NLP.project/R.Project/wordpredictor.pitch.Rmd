---
title: "WordPredictor Pitch"
author: "Douglas Thoms"
date: "December 9, 2019"
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Summary

- Goal - create a model that can predict
- Approach - used stupid back-off algorithm, expanded corpus
- Result - using benchmark.R, here are figures

## WordPredictor App

```{r, echo=FALSE, message=FALSE}
#
# This is the user-interface definition of a Shiny web application. You can
# run the application by clicking 'Run App' above.
#
# Find out more about building applications with Shiny here:
# 
#    http://shiny.rstudio.com/
#
# https://shiny.rstudio.com/articles/layout-guide.html

#https://shiny.rstudio.com/articles/tabsets.html

library(shiny)
library(shinythemes)
library(data.table)
library(ngram)
library(stringr)
library(purrr)
library(dplyr)
library(DT)
library(quanteda)

shinyApp(        
        # Define UI for application that draws a histogram
        ui = navbarPage(theme=shinytheme("spacelab"),
                                 title = 'Word Predictor',
          
          # Sidebar with a slider input for number of bins 
          sidebarLayout(
                  
                  sidebarPanel(
                         p("Predict the next word of a sentence."),
                         p("Enter a sentence to see the predicted words.  Remember to press
                           spacebar before last word.")
                  ),
            
            # Show a plot of the generated distribution
            mainPanel(
                    tabsetPanel(
                            tabPanel("Word Predictor",
                                     p(textInput("entry.sentence","Enter sentence and press spacebar:", "There are")),
                                     #create scroll down button to choose 3-5 predictions
                                     p(    selectInput("number.prediction", "Number of Predictions:",
                                                       c("3" = 3,
                                                         "4" = 4,
                                                         "5" = 5))),
                                     br(),
                                     DT::dataTableOutput("final.results")),
                            
                            tabPanel("About", div(p('This widget predicts words using the ', 
                                                    a(href = 'https://www.aclweb.org/anthology/D07-1090.pdf', 
                                                      'Stupid Back-Off Algorithm', .noWS = "outside"), 
                                                    '.  The sample data (corpus) is a 
                                                    collection of the following sources:', 
                                                    .noWS = c("after-begin", "before-end"))),
                                     tags$ul(
                                             tags$li(p("Partial collection of Gutenberg Project corpus provided by Shibamouli Lahiri: ",
                                                       a(href = 'https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip', 
                                                         'https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip', .noWS = "outside"))),
                                             tags$li(p("Andrew L. Maas, Raymond E. Daly, Peter T. Pham, 
                                                     Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011).",
                                               em("Learning Word Vectors for Sentiment Analysis."),"
                                                     The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011).",
                                               a(href = 'https://ai.stanford.edu/~amaas/data/sentiment/', 'https://ai.stanford.edu/~amaas/data/sentiment/', .noWS = "outside"))
                                               ), 
                                             tags$li(p("Swiftkey provided a dataset which was taken from the following address:",
                                                       a(href = 'https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip', 
                                                         'https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip', .noWS = "outside")))
                                             )
                                )       
                        )
                    )
                )
        ),
        
        # This is the server logic of a Shiny web application. You can run the 
        # application by clicking 'Run App' above.
        #
        # Find out more about building applications with Shiny here:
        # 
        #    http://shiny.rstudio.com/
        #
        

        
        # Define server logic required to draw a histogram
        server = function(input,output){
                
                #rm(list=setdiff(ls(), "final.values"))
                
                file <- ("data/score.table.rds")
                con <- gzfile(file)
                score.table <- readRDS(con)
                close(con)
                
          output$final.results <- DT::renderDataTable({
                  
                  #see if issue here
                  #if loop that waits for complete words based on space
                  if(str_sub(input$entry.sentence, start = -1) == " "){
                        #need a loop in here so only reacts on blank white space
                  
                          #prep search terms
                          entry.cleaned <- input$entry.sentence %>%
                                  tokens(remove_punct = TRUE,
                                         remove_numbers = TRUE,
                                         remove_symbols = TRUE,
                                         remove_url = TRUE,
                                         remove_twitter = TRUE
                                  ) %>%
                                  tokens_tolower()
                          #tokens_select(stopwords('english'),selection='remove')
                          entry.cleaned <- paste(entry.cleaned[[1]],collapse=" ")
                          print(entry.cleaned)
                          
                          #determine string length
                          entry.cleaned.length <- wordcount(entry.cleaned)
                          
                          #if over 4, truncuate to last 4 words
                          if (entry.cleaned.length >4) {
                                  entry.cleaned <- word(entry.cleaned, start = entry.cleaned.length-3, end = entry.cleaned.length)
                                  entry.cleaned.length <- 4
                          }
                          
                          #changes blank spaces to hyphen to match look up tables
                          entry.cleaned <- gsub(" ", "_", entry.cleaned)
                          
                          #create loop to break entry sentence into ngram to unigram
                          output <- NULL
                          
                          for(i in 1:entry.cleaned.length) {
                                  #generate ngrams from blank to pentagram
                                  output <- c(output, word(entry.cleaned, start = i, end = entry.cleaned.length, sep = "_"))
                          }
                          
                          output <- c(output,NA)
                          
                          
                          predictions <- NULL
                          for(i in 1:entry.cleaned.length+1){
                                  
                                  df <- score.table[.(output[i]), nomatch = 0L]
                                  predictions <- rbind(predictions,df)
                                  
                          }
                          
                          
                          #get last word
                          predictions <- predictions %>%
                                  mutate(new.word = map_chr(name,word, start = -1, sep = "_")) %>%
                                  group_by(new.word) %>%
                                  summarise(score = sum(score)) %>%
                                  ungroup %>%
                                  #remove stop words
                                  #filter(!(new.word %in% stopwords("english"))) %>%
                                  arrange(desc(score)) %>%
                                  mutate(predicted.sentence = paste(input$entry.sentence,new.word)) %>%
                                  slice(1:input$number.prediction) %>%
                                  transform(score = round(score,4)) %>%
                                  select(predicted.sentence,score) %>%
                                  rename(Predicted.Sentences = predicted.sentence,
                                         Score = score)
                  
                  }else{
                          predictions <- data.frame(Predicted.Sentences = "Please put in space after last word",
                                                    "Score" = NA)
                  }
          })
        
        }
)

```

## Methodology
### Problem
- Bullet 2
- Bullet 3

### Approach

## Results


