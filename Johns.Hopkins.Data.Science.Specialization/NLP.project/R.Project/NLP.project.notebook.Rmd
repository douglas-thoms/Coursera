---
title: "R Notebook - NLP project"
output: html_notebook
---

Read tm and quanteda packages
https://github.com/lgreski/datasciencectacontent/blob/master/markdown/capstone-ngramComputerCapacity.md
https://www.coursera.org/learn/data-science-project/discussions/all/threads/7HcUyzJXEeeZ1Qo60q6J_A
https://lagunita.stanford.edu/c4x/Engineering/CS-224N/asset/slp4.pdf
https://github.com/rstudio/cheatsheets/raw/master/quanteda.pdf
https://data.library.virginia.edu/a-beginners-guide-to-text-analysis-with-quanteda/
https://www.bnosac.be/index.php/blog/56-an-overview-of-text-mining-visualisations-possibilities-with-r-on-the-ceta-trade-agreement
https://github.com/shuangsong/capstone/blob/master/books/bigram-2x2.pdf
https://cran.r-project.org/web/packages/ngram/ngram.pdf
https://www.coursera.org/learn/data-science-project/discussions/all/threads/V40gAPE3EeWFuw7QEATDpw
https://quanteda.io/articles/quickstart.html

Dictionaries
lexicon package
newsmap

Lemmatization
https://stackoverflow.com/questions/28214148/how-to-perform-lemmatization-in-r/28318683

Research Sources

text processing
http://www.mjdenny.com/Text_Processing_In_R.html

Modelling
Ngrams - ngram package, marko chains
https://rpubs.com/mszczepaniak/predictkbo3model
https://www.analyticsvidhya.com/blog/2014/07/markov-chain-simplified/
https://www.youtube.com/watch?v=UyC0bBiZY-A
Kneser-Ney smoothing
https://rpubs.com/pferriere/dscapreport
http://smithamilli.com/blog/kneser-ney/
https://www.youtube.com/watch?v=eNLUo3AIvcQ
https://en.wikipedia.org/wiki/Katz%27s_back-off_model
http://www.marekrei.com/pub/Machine_Learning_for_Language_Modelling_-_lecture2.pdf
http://adv-r.had.co.nz/memory.html
use kneser-ney or katz


Testing Model and Code Rprof()
Size object.size()
Profiler to test time
http://rpubs.com/mszczepaniak/classificationgoodness
https://github.com/hfoffani/dsci-benchmark


Todo list to improve models

Things to modify
-ngram length - probably not
-are words actually in dictionary including full ngram, check

Correct answers
[1] "You're the reason why I smile everyday. Can you follow me please? It would mean the"
[1] "world"

[1] "Ohhhhh #PointBreak is on tomorrow. Love that film and haven't seen it in quite some"
[1] "time now"

[1] "Well I'm pretty sure my granny has some old bagpipes in her garage I'll dust them off and be on my"
[1] "way starting"

